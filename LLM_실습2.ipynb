{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "t1UrDEEJ7su7"
      },
      "outputs": [],
      "source": [
        "file_path = \"/content/100문 100답 데이터.txt\"\n",
        "with open(file_path, 'r', encoding='utf-8') as f:\n",
        "    raw_data = f.read()\n",
        "\n",
        "template = \"### 질문: {instruction}\\n\\n### 답변: {response}\"\n",
        "\n",
        "formatted_data = []\n",
        "for line in raw_data.strip().split('\\n'):\n",
        "    try:\n",
        "        parts = line.split('\\t', 1)[1].split('|', 1)\n",
        "        instruction = parts[0].strip()\n",
        "        response = parts[1].strip().replace('\"', '')\n",
        "\n",
        "        full_text = template.format(instruction=instruction, response=response)\n",
        "        formatted_data.append({\"text\": full_text})\n",
        "    except:\n",
        "        continue\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q transformers accelerate bitsandbytes peft trl torch"
      ],
      "metadata": {
        "id": "Dv2ZYsEv79G6"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LoRA"
      ],
      "metadata": {
        "id": "ip4L7Sal8HOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from datasets import Dataset\n",
        "\n",
        "model_id = \"EleutherAI/polyglot-ko-1.3b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "model.config.use_cache = False\n",
        "\n",
        "# 3. LoRA 설정 및 모델 적용\n",
        "lora_config = LoraConfig(\n",
        "    r=16, # 랭크 (작을수록 가벼움)\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"query_key_value\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "print(model.print_trainable_parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "5d40b618b8964347a7df41298f7af358",
            "0754b281a8494bf8ba782e92ce8d0455",
            "f56788f687ac44d2986f8fe6400bcb1e",
            "a55dba46d27548e8adbeb6e69d07fc9f",
            "70168a85b2e44768b525674b98b9064d",
            "068c9d56b8f849d0871ac1337669658c",
            "72da8ffeb3844d279cead0674a26946d",
            "5e48ce00302c4287a4bb66ebb95f16d7",
            "3c862c767b2e4bd39f511d9e5a4a95a9",
            "30f236c50d8e4ffa9315a388ba903dae",
            "d28847b984724c4fa417bcd6f2cda126"
          ]
        },
        "id": "N6u_sPpz7-nk",
        "outputId": "c1ced859-8485-4e99-d66f-3f1e873c1191"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d40b618b8964347a7df41298f7af358"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 3,145,728 || all params: 1,334,956,032 || trainable%: 0.2356\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 실행"
      ],
      "metadata": {
        "id": "3acO-UIe8Elj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "dataset = Dataset.from_list(formatted_data)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-4,\n",
        "    logging_steps=25,\n",
        "    save_steps=50,\n",
        "    fp16=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557,
          "referenced_widgets": [
            "50070183dd904fe6acadfcbff3672dd6",
            "056bb9ae57d948b88814e337c96388d4",
            "faa659d982604da0bedb6feaaa98c0b5",
            "f3542afb567c438ca97d54cdcd70ce11",
            "d9f2eba74d8946e186f6feae1749624d",
            "ac268dbaf25b46f5b970b49aa2d1be1f",
            "ac59b6304ae343f980f71e4e27dea2aa",
            "af9a53fa11c0493c9c26f0aecb203aeb",
            "b482cbe209134b459ac6a25859e59df9",
            "17a54a1120aa4b509a44427616ddf0ba",
            "0e8785f94a9a4552ab06ebc4090d2605",
            "8669b019cd1441989292d91a4300f168",
            "11f85f1383314b0e88e9c363b01a291e",
            "5b9f54dd618b45ccb5d5e03755e11d86",
            "56d034ed355a44a782f4451d8a797041",
            "e733b42cf16a41248cc04a7d33708207",
            "28270449b310412caaea6a6706325bf4",
            "666a69494be041408f19aa67c7af2ac4",
            "879da51e19b549fdb7b6a0680e9a97f9",
            "8b4e89a2ccba4fd2967b08e2b69a0c4c",
            "0c7be05bf47a46318db322e63c06027d",
            "9a1512a71bdc4721918f91b46a439c2c",
            "0d7b2f66e3e64b14b274dbf19b3baa57",
            "5fc9941792cc4959ad086030559100bb",
            "aa0914d9137e4c97896a517e8b69d583",
            "d1d95bd97ee4477b99dc00c1140ff227",
            "d6d8e4ef5fbb47baae875e3880b3c202",
            "d73fbc472bf345bb8c24e08508a90864",
            "42664e4ff14e4c71a9d9f47fae27279a",
            "96829adc4a644b32a29c0dfa3da18e9b",
            "071d6b867eea4b64a674f4fe1b0402e4",
            "1f6e8930f01248ac868d9ea5761c9696",
            "2fc6c2a7f29049cf9b9bbad927960056"
          ]
        },
        "id": "WZ8jjBJf8Ac8",
        "outputId": "359dac37-0e92-4e47-f2b8-e179ae5bad54"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Adding EOS to train dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50070183dd904fe6acadfcbff3672dd6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8669b019cd1441989292d91a4300f168"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d7b2f66e3e64b14b274dbf19b3baa57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 2}.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 02:01, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>3.669500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.492600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.172400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.010400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.858000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.713700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.592900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.500800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.440800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.405200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=250, training_loss=1.0856275787353515, metrics={'train_runtime': 122.0553, 'train_samples_per_second': 8.193, 'train_steps_per_second': 2.048, 'total_flos': 174194579865600.0, 'train_loss': 1.0856275787353515, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과 확인"
      ],
      "metadata": {
        "id": "fCTLjmoy8CsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 모델 저장\n",
        "trainer.model.save_pretrained(\"./fine-tuned-model\")"
      ],
      "metadata": {
        "id": "rGJgp4Jg8Bpx"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts = [\n",
        "    \"### 질문: 좋아하는 가수\\n\",\n",
        "    \"### 질문: 가장 좋아하는 과목이 뭐야?\\n\",\n",
        "    \"### 질문: 취미는 뭐야?\\n\",\n",
        "    \"### 질문: 나의 좌우명\\n\"\n",
        "]\n",
        "\n",
        "for input_text in input_texts:\n",
        "    print(f\"{input_text.strip()}\")\n",
        "\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\", return_token_type_ids=False).to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(**inputs, max_new_tokens=50, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    print(f\"{response.replace(input_text, '').strip()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3UyzDP7-gIp",
        "outputId": "57461d9d-6226-487c-cc51-1c48e464d8fa"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### 질문: 좋아하는 가수\n",
            "### 답변: 에스파, 엔믹스\n",
            "\n",
            "### 질문: 가장 좋아하는 과목이 뭐야?\n",
            "### 답변: 과학\n",
            "\n",
            "### 질문: 취미는 뭐야?\n",
            "### 답변: 인터넷 쇼핑하기\n",
            "\n",
            "### 질문: 나의 좌우명\n",
            "### 답변: 없음\n",
            "\n"
          ]
        }
      ]
    }
  ]
}