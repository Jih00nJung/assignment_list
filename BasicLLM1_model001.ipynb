{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSkPcFhpgNzwAo1IHANdyt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jih00nJung/assignment_list/blob/main/BasicLLM1_model001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cL4ofM0le-jA",
        "outputId": "3460f710-794a-4d3e-baaa-12268426032d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cleaned_Jekyll and Hyde.txt 157432 characters\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_text(filename):\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        book_text = file.read()\n",
        "\n",
        "    cleaned_text = re.sub(r'\\n+', ' ', book_text) # 줄바꿈을 빈칸으로 변경\n",
        "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) # 여러 빈칸을 하나의 빈칸으로\n",
        "\n",
        "    print(\"cleaned_\" + filename, len(cleaned_text), \"characters\") # 글자 수 출력\n",
        "\n",
        "    with open(\"cleaned_\" + filename, 'w', encoding='utf-8') as file:\n",
        "        file.write(cleaned_text)\n",
        "\n",
        "filenames_list = [\"Jekyll and Hyde.txt\"]\n",
        "\n",
        "for filename in filenames_list:\n",
        "    clean_text(filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p-kT1E8fGWX",
        "outputId": "3ae3332d-9c31-4e43-e7a9-8b10a093fe4d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken # pip install tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "text = \"Mr. Utterson the lawyer was a man of a rugged countenance that was never lighted by a smile;\"\n",
        "\n",
        "tokens = tokenizer.encode(text)\n",
        "\n",
        "print(\"글자수:\", len(text), \"토큰수\", len(tokens))\n",
        "print(tokens)\n",
        "print(tokenizer.decode(tokens))\n",
        "for t in tokens:\n",
        "    print(f\"{t}\\t -> {tokenizer.decode([t])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG1LMRhafIB7",
        "outputId": "8afcee33-2f5a-4caf-9a09-c9167279d15f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "글자수: 92 토큰수 23\n",
            "[5246, 13, 7273, 23192, 262, 6853, 373, 257, 582, 286, 257, 30957, 954, 36368, 326, 373, 1239, 1657, 276, 416, 257, 8212, 26]\n",
            "Mr. Utterson the lawyer was a man of a rugged countenance that was never lighted by a smile;\n",
            "5246\t -> Mr\n",
            "13\t -> .\n",
            "7273\t ->  Ut\n",
            "23192\t -> terson\n",
            "262\t ->  the\n",
            "6853\t ->  lawyer\n",
            "373\t ->  was\n",
            "257\t ->  a\n",
            "582\t ->  man\n",
            "286\t ->  of\n",
            "257\t ->  a\n",
            "30957\t ->  rugged\n",
            "954\t ->  count\n",
            "36368\t -> enance\n",
            "326\t ->  that\n",
            "373\t ->  was\n",
            "1239\t ->  never\n",
            "1657\t ->  light\n",
            "276\t -> ed\n",
            "416\t ->  by\n",
            "257\t ->  a\n",
            "8212\t ->  smile\n",
            "26\t -> ;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for char in text:\n",
        "    token_ids = tokenizer.encode(char)     # 한 글자씩 인코딩(토큰화)\n",
        "    decoded = tokenizer.decode(token_ids)  # 한 글자씩 디코딩\n",
        "    print(f\"{char} -> {token_ids} -> {decoded}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsNDKy_sfJna",
        "outputId": "f70d636c-e92c-42ae-8d8c-b78322430334"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M -> [44] -> M\n",
            "r -> [81] -> r\n",
            ". -> [13] -> .\n",
            "  -> [220] ->  \n",
            "U -> [52] -> U\n",
            "t -> [83] -> t\n",
            "t -> [83] -> t\n",
            "e -> [68] -> e\n",
            "r -> [81] -> r\n",
            "s -> [82] -> s\n",
            "o -> [78] -> o\n",
            "n -> [77] -> n\n",
            "  -> [220] ->  \n",
            "t -> [83] -> t\n",
            "h -> [71] -> h\n",
            "e -> [68] -> e\n",
            "  -> [220] ->  \n",
            "l -> [75] -> l\n",
            "a -> [64] -> a\n",
            "w -> [86] -> w\n",
            "y -> [88] -> y\n",
            "e -> [68] -> e\n",
            "r -> [81] -> r\n",
            "  -> [220] ->  \n",
            "w -> [86] -> w\n",
            "a -> [64] -> a\n",
            "s -> [82] -> s\n",
            "  -> [220] ->  \n",
            "a -> [64] -> a\n",
            "  -> [220] ->  \n",
            "m -> [76] -> m\n",
            "a -> [64] -> a\n",
            "n -> [77] -> n\n",
            "  -> [220] ->  \n",
            "o -> [78] -> o\n",
            "f -> [69] -> f\n",
            "  -> [220] ->  \n",
            "a -> [64] -> a\n",
            "  -> [220] ->  \n",
            "r -> [81] -> r\n",
            "u -> [84] -> u\n",
            "g -> [70] -> g\n",
            "g -> [70] -> g\n",
            "e -> [68] -> e\n",
            "d -> [67] -> d\n",
            "  -> [220] ->  \n",
            "c -> [66] -> c\n",
            "o -> [78] -> o\n",
            "u -> [84] -> u\n",
            "n -> [77] -> n\n",
            "t -> [83] -> t\n",
            "e -> [68] -> e\n",
            "n -> [77] -> n\n",
            "a -> [64] -> a\n",
            "n -> [77] -> n\n",
            "c -> [66] -> c\n",
            "e -> [68] -> e\n",
            "  -> [220] ->  \n",
            "t -> [83] -> t\n",
            "h -> [71] -> h\n",
            "a -> [64] -> a\n",
            "t -> [83] -> t\n",
            "  -> [220] ->  \n",
            "w -> [86] -> w\n",
            "a -> [64] -> a\n",
            "s -> [82] -> s\n",
            "  -> [220] ->  \n",
            "n -> [77] -> n\n",
            "e -> [68] -> e\n",
            "v -> [85] -> v\n",
            "e -> [68] -> e\n",
            "r -> [81] -> r\n",
            "  -> [220] ->  \n",
            "l -> [75] -> l\n",
            "i -> [72] -> i\n",
            "g -> [70] -> g\n",
            "h -> [71] -> h\n",
            "t -> [83] -> t\n",
            "e -> [68] -> e\n",
            "d -> [67] -> d\n",
            "  -> [220] ->  \n",
            "b -> [65] -> b\n",
            "y -> [88] -> y\n",
            "  -> [220] ->  \n",
            "a -> [64] -> a\n",
            "  -> [220] ->  \n",
            "s -> [82] -> s\n",
            "m -> [76] -> m\n",
            "i -> [72] -> i\n",
            "l -> [75] -> l\n",
            "e -> [68] -> e\n",
            "; -> [26] -> ;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqvsLq-KfLRe",
        "outputId": "1cb6d583-4d30-4198-b43b-744e646bfbae"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, txt, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # token_ids = tokenizer.encode(\"<|endoftext|>\" + txt, allowed_special={\"<|endoftext|>\"})\n",
        "        token_ids = tokenizer.encode(txt)\n",
        "\n",
        "        print(\"# of tokens in txt:\", len(token_ids))\n",
        "\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "# with open(\"cleaned_한글문서.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
        "with open(\"cleaned_Jekyll and Hyde.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
        "    txt = file.read()\n",
        "\n",
        "dataset = MyDataset(txt, max_length = 32, stride = 4)\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)\n",
        "\n",
        "# 주의: 여기서는 코드를 단순화하기 위해 test, valid는 생략하고 train_loader만 만들었습니다.\n",
        "#      관련된 ML 이론이 궁금하신 분들은 train vs test vs validation 등으로 검색해보세요."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FcL6dVLfM5z",
        "outputId": "8dbe0b0c-242e-4d7f-ac91-b5b9294ac0f5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of tokens in txt: 38096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_loader)\n",
        "\n",
        "x, y = next(dataiter)\n",
        "\n",
        "print(tokenizer.decode(x[0].tolist()))\n",
        "print(tokenizer.decode(y[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPUkWDukfObw",
        "outputId": "0d0ad91f-5557-48c2-8ace-0ad2550f9cd2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " time scarce, at night under the face of the fogged city moon, by all lights and at all hours of solitude or concourse, the lawyer was to\n",
            " scarce, at night under the face of the fogged city moon, by all lights and at all hours of solitude or concourse, the lawyer was to be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델을 정의할 때 사용하는 상수들\n",
        "\n",
        "VOCAB_SIZE = tokenizer.n_vocab # 50257 Tiktoken\n",
        "#VOCAB_SIZE = len(tokenizer) # AutoTokenizer\n",
        "CONTEXT_LENGTH = 128  # Shortened context length (orig: 1024)\n",
        "EMB_DIM = 768  # Embedding dimension\n",
        "NUM_HEADS = 12  # Number of attention heads\n",
        "NUM_LAYERS = 12  # Number of layers\n",
        "DROP_RATE = 0.1  # Dropout rate\n",
        "QKV_BIAS = False  # Query-key-value bias"
      ],
      "metadata": {
        "id": "UuV6R7oYfPtr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out):\n",
        "        super().__init__()\n",
        "\n",
        "        assert d_out % NUM_HEADS == 0, \"d_out must be divisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.head_dim = d_out // NUM_HEADS\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(DROP_RATE)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(CONTEXT_LENGTH, CONTEXT_LENGTH), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)  # (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
        "        values = values.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
        "\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(EMB_DIM, 4 * EMB_DIM),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * EMB_DIM, EMB_DIM),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=EMB_DIM,\n",
        "            d_out=EMB_DIM)\n",
        "\n",
        "        self.ff = FeedForward()\n",
        "        self.norm1 = LayerNorm(EMB_DIM)\n",
        "        self.norm2 = LayerNorm(EMB_DIM)\n",
        "        self.drop_shortcut = nn.Dropout(DROP_RATE)\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
        "        self.pos_emb = nn.Embedding(CONTEXT_LENGTH, EMB_DIM)\n",
        "        self.drop_emb = nn.Dropout(DROP_RATE)\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock() for _ in range(NUM_LAYERS)])\n",
        "\n",
        "        self.final_norm = LayerNorm(EMB_DIM)\n",
        "        self.out_head = nn.Linear(EMB_DIM, VOCAB_SIZE, bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "nJ5E82L8fQ1B"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device = \"cpu\"\n",
        "print(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel()\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv8ExMPCfSyL",
        "outputId": "85735804-b8b2-44dd-e8d1-58f301c963ff"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_seen, global_step = 0, -1\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    epoch_loss = 0\n",
        "    for input_batch, target_batch in train_loader:\n",
        "        optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "        logits = model(input_batch)\n",
        "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward() # Calculate loss gradients\n",
        "        optimizer.step() # Update model weights using loss gradients\n",
        "        tokens_seen += input_batch.numel()\n",
        "        global_step += 1\n",
        "\n",
        "        if global_step % 1000 == 0:\n",
        "            print(f\"Tokens seen: {tokens_seen}\")\n",
        "        # Optional evaluation step\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    losses.append(avg_loss)\n",
        "    print(f\"Epoch: {epoch + 1}, Loss: {avg_loss}\")\n",
        "    torch.save(model.state_dict(), \"model_\" + str(epoch + 1).zfill(3) + \".pth\")\n",
        "\n",
        "# 주의: 여기서는 편의상 모든 데이터를 train에 사용하였습니다.\n",
        "#      ML에서는 일부 데이터를 validation에 사용하는 것이 일반적입니다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf-DKdw7fTuL",
        "outputId": "198c5ad3-0835-45b7-fbc7-d0dc46130b92"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens seen: 4096\n",
            "Epoch: 1, Loss: 5.746674627871127\n",
            "Epoch: 2, Loss: 3.61037726015658\n",
            "Epoch: 3, Loss: 1.905399478770591\n",
            "Epoch: 4, Loss: 0.6795147540601524\n",
            "Epoch: 5, Loss: 0.32458327227347605\n",
            "Epoch: 6, Loss: 0.23760075081844587\n",
            "Epoch: 7, Loss: 0.20704059886771278\n",
            "Epoch: 8, Loss: 0.18959161941264127\n",
            "Epoch: 9, Loss: 0.1784535428962192\n",
            "Epoch: 10, Loss: 0.1722899131678246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.show()\n",
        "\n",
        "# 보충: validation loss를 같이 그려서 비교하는 사례 https://www.geeksforgeeks.org/training-and-validation-loss-in-deep-learning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "EQrJ2zUOfVD9",
        "outputId": "732d2497-0aaf-40ac-8c45-eae3ce4d2bcd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일로 저장했던 네트워크의 가중치들 읽어들이기\n",
        "model.load_state_dict(torch.load(\"model_001.pth\", map_location=device, weights_only=True))\n",
        "model.eval() # dropout을 사용하지 않음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM_T5Bs0fWFW",
        "outputId": "43001207-672b-4c20-98d0-381058030c13"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(128, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = tokenizer.encode(\"Dobby is\") # 토큰 id의 list\n",
        "idx = torch.tensor(idx).unsqueeze(0).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(idx)\n",
        "\n",
        "logits = logits[:, -1, :]\n",
        "\n",
        "# 가장 확률이 높은 단어 10개 출력\n",
        "top_logits, top_indices = torch.topk(logits, 10)\n",
        "for p, i in zip(top_logits.squeeze(0).tolist(), top_indices.squeeze(0).tolist()):\n",
        "    print(f\"{p:.2f}\\t {i}\\t {tokenizer.decode([i])}\")\n",
        "\n",
        "# 가장 확률이 높은 단어 출력\n",
        "idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "flat = idx_next.squeeze(0) # 배치 차원 제거 torch.Size([1])\n",
        "out = tokenizer.decode(flat.tolist()) # 텐서를 리스트로 바꿔서 디코드\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lnTigFQfW_t",
        "outputId": "c224a248-5e21-4d65-bf3b-d3e1f5639f12"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.83\t 635\t  also\n",
            "9.50\t 257\t  a\n",
            "9.36\t 10944\t  derived\n",
            "8.34\t 6507\t  sad\n",
            "8.11\t 991\t  still\n",
            "7.79\t 5421\t  bound\n",
            "7.03\t 5884\t  connected\n",
            "6.90\t 530\t  one\n",
            "6.77\t 8631\t  plain\n",
            "6.54\t 880\t  well\n",
            " also\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        if top_k is not None:\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
        "\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
        "\n",
        "        if idx_next == eos_id:\n",
        "            break\n",
        "\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "xpOmuXrpfYIp"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_context = input(\"Start context: \")\n",
        "\n",
        "# idx = tokenizer.encode(start_context, allowed_special={'<|endoftext|>'})\n",
        "idx = tokenizer.encode(start_context)\n",
        "idx = torch.tensor(idx).unsqueeze(0)\n",
        "\n",
        "context_size = model.pos_emb.weight.shape[0]\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=idx.to(device),\n",
        "        max_new_tokens=50,\n",
        "        context_size= context_size,\n",
        "        top_k=50,\n",
        "        temperature=0.5\n",
        "    )\n",
        "\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    out = tokenizer.decode(flat.tolist()).replace(\"\\n\", \" \")\n",
        "\n",
        "    print(i, \":\", out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnnrHIJPfZdW",
        "outputId": "5ec39606-12b1-4156-e8bf-836f18ab5135"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start context: hyde\n",
            "0 : hyde. The lawyer put it in his pocket. “I would say nothing of this paper. If your master has fled or is dead, we may at least save his fears incline to make any degree of your sake, we may at least save\n",
            "1 : hyde. The lawyer put it in his pocket. “I would say nothing of this paper. If your master has fled or is dead, we may at least save his head like a question, we may be used to be more than myself when you\n",
            "2 : hyde, like a district of some city in a nightmare. The thoughts of his mind, besides, were of the gloomiest dye; and when he glanced at the change a somewhat theatrical to hope me in one of his companion seemed to another begins, he\n",
            "3 : hyde of self-defence. Twelve o’clock had scarce rung out over London, ere the knocker sounded very gently on the door. I went so disagreeably preoccupied his shoulder as he went so long ago. I went so\n",
            "4 : hyde of wonder at my vicarious depravity. This familiar that I called out of my own soul, and sent forth alone to do his good pleasure, was a being a being a being a being posted with a being a being a being a being a\n",
            "5 : hyde. The lawyer put it in his pocket. “I would say nothing of this paper. If your master has fled or is dead, we may at least save his head goes round that?” said complainingly and let us make a great\n",
            "6 : hyde of the spirit that man is not truly one, but truly two. I say two, because the state of my own knowledge does not pass beyond that point. Others will follow, another man, where one point. Others will walk into a certain Mr\n",
            "7 : hyde of the scaffold. Jekyll was now my city of refuge; let but Hyde peep out an instant, and the hands of all men would be early part of all men would be destroyed my disposition, I would be raised to take a\n",
            "8 : hyde. The lawyer liked this letter well enough; it put a better colour on the intimacy than he had looked for; and he blamed himself for some of his past suspicions. “Have you can bear. He would have been told Mr. He cannot\n",
            "9 : hyde. The lawyer put it in his pocket. “I would say nothing of this paper. If your master has fled or is dead, we may at least save his head goes round some strange clauses of least save “but can be explained.\n"
          ]
        }
      ]
    }
  ]
}